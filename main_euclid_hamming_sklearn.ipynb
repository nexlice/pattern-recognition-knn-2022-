{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting loading data...\n",
      "successfully loaded data.\n",
      "number of data = 20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"starting loading data...\")\n",
    "#같은 디렉토리 내에 있는 csv파일을 탐색합니다.\n",
    "filename_data = './satisfaction_data.csv'\n",
    "\n",
    "#0~5번째 열은 feature로, 6번째 열은 class데이터로 저장합니다.\n",
    "data_feature = np.loadtxt(filename_data, delimiter =',',usecols= (0,1,2,3,4,5), dtype=int)\n",
    "data_class = np.loadtxt(filename_data, delimiter =',',usecols= (6), dtype='str')\n",
    "number_data = data_feature.shape[0]\n",
    "\n",
    "print(\"successfully loaded data.\")\n",
    "print(\"number of data = \" + str(number_data))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data inspection\n",
      "data_col_0\n",
      "min:1.0\n",
      "max:99.0\n",
      "mean:43.22015\n",
      "var:140.24748397747882\n",
      "\n",
      "data_col_1\n",
      "min:0.0\n",
      "max:5.0\n",
      "mean:2.3586\n",
      "var:1.2923060399996893\n",
      "\n",
      "data_col_2\n",
      "min:0.0\n",
      "max:2.0\n",
      "mean:1.1708\n",
      "var:0.31852736000004944\n",
      "\n",
      "data_col_3\n",
      "min:13769.0\n",
      "max:1097453.0\n",
      "mean:184706.98085\n",
      "var:10226020824.74352\n",
      "\n",
      "data_col_4\n",
      "min:17.0\n",
      "max:90.0\n",
      "mean:39.4344\n",
      "var:165.8094966400004\n",
      "\n",
      "data_col_5\n",
      "min:1.0\n",
      "max:16.0\n",
      "mean:10.30435\n",
      "var:6.026421077499933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#추후 normalization을 위한 minmax를 저장합니다.\n",
    "#그리고 데이터의 전체적인 분포를 가늠하기위해\n",
    "#각 열마다, 즉, 각 파라미터마다 최소, 최대, 평균, 분산을 출력합니다.\n",
    "\n",
    "print(\"data inspection\")\n",
    "minmax = np.empty((6,2), float)\n",
    "\n",
    "for i in range(6):\n",
    "    print(\"data_col_\"+str(i))\n",
    "    minmax[i][0] = np.min(data_feature, axis=0)[i]\n",
    "    print(\"min:\"+str(minmax[i][0]))\n",
    "    minmax[i][1] = np.max(data_feature, axis=0)[i]\n",
    "    print(\"max:\"+str(minmax[i][1]))\n",
    "    print(\"mean:\"+str(np.mean(data_feature, axis=0)[i]))\n",
    "    print(\"var:\"+str(np.var(data_feature, axis=0)[i]))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting normalization...\n",
      "[[0.39795918 0.4        0.5        0.06745786 0.10958904 0.53333333]\n",
      " [0.39795918 0.4        0.5        0.22659188 0.50684932 0.6       ]\n",
      " [0.39795918 0.4        0.5        0.22427571 0.35616438 0.86666667]\n",
      " ...\n",
      " [0.39795918 0.4        0.5        0.15553796 0.20547945 0.26666667]\n",
      " [0.39795918 0.6        0.5        0.03829806 0.4109589  0.6       ]\n",
      " [0.5        0.8        0.5        0.04785066 0.24657534 0.8       ]]\n",
      "data is normalized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 거리를 구할 때 유클리드 거리 (l2 norm)으로 구합니다.\n",
    "# 한 요소의 범위가 너무 크다면, 그 feature때문에 다른 값들이 trivial 해집니다.\n",
    "# 데이터의 분포 모두 최소가 0, 최대가 1이 되도록 normalization을 해줍니다.\n",
    "print(\"starting normalization...\")\n",
    "normalized = np.empty((20000,6))\n",
    "#print(normalized.shape[1])\n",
    "for i in range(normalized.shape[1]):\n",
    "    normalized[:, i] = (data_feature[:, i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "print(normalized)\n",
    "print(\"data is normalized.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# augment feature and class data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터를 섞을 때 feature와 class가 함께 이동하도록 데이터를 합쳐줍니다.\n",
    "data_augmented = np.concatenate((normalized, data_class.reshape(20000, 1)), axis = 1)\n",
    "\n",
    "#추후 계산의 편의를 위해 unsatisfied 는 0으로, satisfied는 1로 바꿉니다.\n",
    "np.putmask(data_augmented, data_augmented == 'satisfied', 1)\n",
    "np.putmask(data_augmented, data_augmented == 'unsatisfied', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "## train data set, test data set separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting sampling data...\n",
      "sample_train_x : (10, 18000, 6)\n",
      "sample_train_y : (10, 18000, 1)\n",
      "sample_test_x : (10, 2000, 6)\n",
      "sample_test_y : (10, 2000, 1)\n",
      "successfully sampled data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터의 총 개수는 20000개로, 1:9로 나누면 2000, 18000입니다.\n",
    "#훈련데이터에 사용할 데이터를 18000, 테스트에 사용할 데이터를 2000개로 설정합니다.\n",
    "#0~19999의 숫자 중에서 2000개를 샘플링한다.\n",
    "\n",
    "print(\"starting sampling data...\")\n",
    "\n",
    "sample_train_x = np.empty((10, 18000, 6))\n",
    "sample_train_y = np.empty((10, 18000, 1))\n",
    "sample_test_x = np.empty((10, 2000, 6))\n",
    "sample_test_y = np.empty((10, 2000, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    data_augmented_mixed = np.random.permutation(data_augmented).reshape(1, 20000, 7)\n",
    "    sample_train_x[i], sample_test_x[i] = data_augmented_mixed[0, 2000:, :6], data_augmented_mixed[0, :2000, :6]\n",
    "    sample_train_y[i], sample_test_y[i] = data_augmented_mixed[0, 2000:, 6].reshape(1, 18000, 1), data_augmented_mixed[0, :2000, 6].reshape(1, 2000, 1)\n",
    "print(\"sample_train_x : \" +str(sample_train_x.shape))\n",
    "print(\"sample_train_y : \" +str(sample_train_y.shape))\n",
    "print(\"sample_test_x : \" +str(sample_test_x.shape))\n",
    "print(\"sample_test_y : \" +str(sample_test_y.shape))\n",
    "print(\"successfully sampled data.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute distance > matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting calculating distance by matrix...\n",
      "(10, 2000, 18000)\n",
      "successfully done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#euclid_dist_matrix에는, \n",
    "#샘플마다 각 test_x에 대해서 모든 train_x에 대한 거리를 저장한다.\n",
    "\n",
    "print(\"starting calculating distance by matrix...\") \n",
    "number_train = sample_train_x.shape[1]\n",
    "number_test = sample_test_x.shape[1]\n",
    "euclid_dists_matrix = np.zeros((10, number_test, number_train))\n",
    "for i in range(10):\n",
    "    test_matrix = np.sum(np.square(sample_test_x[i]), axis=1).reshape(number_test, 1)\n",
    "    train_matrix = np.sum(np.square(sample_train_x[i]), axis=1).reshape(1, number_train)\n",
    "    euclid_dists_matrix[i] = np.sqrt(test_matrix + train_matrix -2*np.dot(sample_test_x[i], sample_train_x[i].T))\n",
    "print(euclid_dists_matrix.shape)\n",
    "print(\"successfully done.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting prediction for 10 data sets...\n",
      "prediction : (1, 10, 2000)\n",
      "successfully done.\n"
     ]
    }
   ],
   "source": [
    "# k 로 지정한 수를 리스트로 저장해주면, 각 k에 대해서 연산합니다.\n",
    "# 앞서서 최적의 k 에 대해서 논의했으므로, 지금은 하나의 k에 대해서만 계산합니다.\n",
    "print(\"starting prediction for 10 data sets...\")\n",
    "k = [5]\n",
    "prediction = np.empty((len(k), 10, number_test))\n",
    "\n",
    "iteration = 0\n",
    "for k_num in k:\n",
    "    for i in range(10):\n",
    "        for j in range(number_test):\n",
    "            neareast_class = []\n",
    "            \n",
    "            #argsort는 넘파이 행렬을 인풋으로 받습니다.\n",
    "            #받은 행렬을 오름차순으로 정렬하여,\n",
    "            #정렬된 요소들의 인덱스를 반환합니다..\n",
    "\n",
    "            #즉, np.argsort(euclid_dists_matrix[i][j]) 부분은\n",
    "            #i번째 샘플의 j번째 테스트케이스에 대해서 모든 값들을 정렬하고,\n",
    "            #정렬된 요소들의 정렬되기 전 인덱스를 반환합니다.\n",
    "            #즉, j번째 test_x와 가장 가까운 순서부터 먼 순서까지 (오름차순으로 정렬했으므로) \n",
    "            #train_x의 인덱스를 반환합니다.\n",
    "            #여기서 k번째까지를 가져와 nearest class에 저장합니다.\n",
    "            neareast_class = sample_train_y[i][np.argsort(euclid_dists_matrix[i][j])][:k_num]\n",
    "\n",
    "            #저장 형식을 갖게 지정한다.\n",
    "            neareast_class = neareast_class.astype(int)\n",
    "\n",
    "            #bincount란 non negative integer로 구성된 넘파이 배열에서\n",
    "            #각각의 빈도수를 세는데 사용하는 메소드입니다.\n",
    "            #0부터 가장 큰 값까지 각각의 발생 빈도수를 체크합니다.\n",
    "            #정답 클래스는 0(unsatisfied), 1(satisfied) 이므로\n",
    "            #[n m] (n, m은 0 이상의 정수)를 반환합니다.\n",
    "            #n은 0인 값들의 개수, m은 1인 값들의 개수입니다.\n",
    "\n",
    "            #argmax는 인풋으로 받은 행렬 중에서\n",
    "            #가장 값이 큰 인덱스를 반환합니다.\n",
    "            #즉, n이 m보다 크다면 n의 인덱스, 0을 반환합니다.\n",
    "            #이 인덱스는 결국 클래스를 나타내게 됩니다.\n",
    "            prediction[iteration][i][j] = np.argmax(np.bincount(neareast_class.reshape(k_num, )))\n",
    "    iteration = iteration + 1\n",
    "print(\"prediction : \" +str(prediction.shape))\n",
    "print(\"successfully done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare prediction and real class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction result for each sample.\n",
      "k: 5\n",
      "sample: 1  accuracy: 76.14999999999999\n",
      "sample: 2  accuracy: 75.75\n",
      "sample: 3  accuracy: 76.64999999999999\n",
      "sample: 4  accuracy: 76.25\n",
      "sample: 5  accuracy: 74.55000000000001\n",
      "sample: 6  accuracy: 74.05000000000001\n",
      "sample: 7  accuracy: 75.75\n",
      "sample: 8  accuracy: 74.75\n",
      "sample: 9  accuracy: 75.4\n",
      "sample: 10  accuracy: 75.55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 지정한 k 값들에 대해서 추정 값이 맞는지 확인합니다.\n",
    "\n",
    "print(\"prediction result for each sample.\")\n",
    "for k_iter in range(len(k)):\n",
    "    print(\"k: \" + str(k[k_iter]))\n",
    "    isAnswer = np.empty((10, 2000))\n",
    "    #isAnswer에는 정답 - 추정한 클래스 값이 들어가 있습니다. \n",
    "    #즉, 요소가 0일 경우 해당 인덱스는 정답이고, \n",
    "    #그 이외의 경우 오답입니다.\n",
    "    isAnswer = sample_test_y - prediction[k_iter].reshape(10, number_test, 1)\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"sample: \" + str(i+1) +\"  accuracy: \"+str((np.count_nonzero(isAnswer[i] == 0)/number_test)*100))\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute by hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2000, 18000)\n"
     ]
    }
   ],
   "source": [
    "#해밍 거리란 두 벡터간의 공통된 값의 수입니다.\n",
    "#비트간 해밍거리는 같아지기 위해서 바꿔야하는 비트의 값이 해밍거리가 됩니다.\n",
    "#즉, 해밍거리의 값이 커질 수록 유사도가 낮다고 할 수 있습니다. \n",
    "#해밍거리가 작다 = 유사도가 높다 = 가깝다.\n",
    "#비트간 해밍거리를 구하기위해서는 XOR연산을 한 후, 1의 개수를 count 합니다.\n",
    "#여기선 normalization이 필요없기 때문에 그대로 raw값을 사용합니다.\n",
    "\n",
    "data_raw_augmented = np.concatenate((data_feature, data_class.reshape(20000, 1)), axis = 1)\n",
    "np.putmask(data_raw_augmented, data_raw_augmented == 'satisfied', 1)\n",
    "np.putmask(data_raw_augmented, data_raw_augmented == 'unsatisfied', 0)\n",
    "#print(data_raw_augmented)\n",
    "\n",
    "sample_raw_train_x = np.empty((10, 18000, 6))\n",
    "sample_raw_train_y = np.empty((10, 18000, 1))\n",
    "sample_raw_test_x = np.empty((10, 2000, 6))\n",
    "sample_raw_test_y = np.empty((10, 2000, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    data_raw_augmented_mixed = np.random.permutation(data_raw_augmented).reshape(1, 20000, 7)\n",
    "    sample_raw_train_x[i], sample_raw_test_x[i] = data_raw_augmented_mixed[0, 2000:, :6], data_raw_augmented_mixed[0, :2000, :6]\n",
    "    sample_raw_train_y[i], sample_raw_test_y[i] = data_raw_augmented_mixed[0, 2000:, 6].reshape(1, 18000, 1), data_raw_augmented_mixed[0, :2000, 6].reshape(1, 2000, 1)\n",
    "\n",
    "#메모리 초과방지를 위해 타입 지정\n",
    "subtracted_matrix = np.zeros((10, number_test, number_train, 6), int)\n",
    "subtracted_logical_xor = np.zeros((10, number_test, number_train, 6), bool)\n",
    "hamming_dists_matrix = np.zeros((10, number_test, number_train))\n",
    "\n",
    "#해밍 거리로 변환\n",
    "for i in range(10):\n",
    "    subtracted_matrix[i] = sample_raw_test_x[i].reshape(number_test, 1, 6) - sample_raw_train_x[i].reshape(1, number_train, 6)\n",
    "    subtracted_logical_xor[i] = np.logical_xor(subtracted_matrix[i], 0)\n",
    "    sameistrue = np.logical_not(subtracted_logical_xor[i])\n",
    "    hamming_dists_matrix[i] = sameistrue.sum(axis=2)\n",
    "print(hamming_dists_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 11  accuracy: 53.400000000000006\n",
      "k: 11  accuracy: 53.949999999999996\n",
      "k: 11  accuracy: 51.0\n",
      "k: 11  accuracy: 51.05\n",
      "k: 11  accuracy: 52.349999999999994\n",
      "k: 11  accuracy: 53.5\n",
      "k: 11  accuracy: 55.65\n",
      "k: 11  accuracy: 54.0\n",
      "k: 11  accuracy: 54.900000000000006\n",
      "k: 11  accuracy: 55.85\n",
      "\n",
      "\n",
      "k: 13  accuracy: 53.400000000000006\n",
      "k: 13  accuracy: 53.5\n",
      "k: 13  accuracy: 52.5\n",
      "k: 13  accuracy: 51.449999999999996\n",
      "k: 13  accuracy: 52.7\n",
      "k: 13  accuracy: 53.300000000000004\n",
      "k: 13  accuracy: 56.65\n",
      "k: 13  accuracy: 54.800000000000004\n",
      "k: 13  accuracy: 56.25\n",
      "k: 13  accuracy: 55.800000000000004\n",
      "\n",
      "\n",
      "k: 15  accuracy: 53.349999999999994\n",
      "k: 15  accuracy: 55.25\n",
      "k: 15  accuracy: 53.15\n",
      "k: 15  accuracy: 51.300000000000004\n",
      "k: 15  accuracy: 52.349999999999994\n",
      "k: 15  accuracy: 52.900000000000006\n",
      "k: 15  accuracy: 57.25\n",
      "k: 15  accuracy: 55.1\n",
      "k: 15  accuracy: 55.2\n",
      "k: 15  accuracy: 56.3\n",
      "\n",
      "\n",
      "k: 17  accuracy: 53.800000000000004\n",
      "k: 17  accuracy: 54.449999999999996\n",
      "k: 17  accuracy: 53.15\n",
      "k: 17  accuracy: 51.5\n",
      "k: 17  accuracy: 52.900000000000006\n",
      "k: 17  accuracy: 53.15\n",
      "k: 17  accuracy: 57.599999999999994\n",
      "k: 17  accuracy: 55.2\n",
      "k: 17  accuracy: 55.800000000000004\n",
      "k: 17  accuracy: 56.05\n",
      "\n",
      "\n",
      "k: 19  accuracy: 52.849999999999994\n",
      "k: 19  accuracy: 54.949999999999996\n",
      "k: 19  accuracy: 53.7\n",
      "k: 19  accuracy: 52.449999999999996\n",
      "k: 19  accuracy: 52.400000000000006\n",
      "k: 19  accuracy: 54.300000000000004\n",
      "k: 19  accuracy: 57.15\n",
      "k: 19  accuracy: 54.65\n",
      "k: 19  accuracy: 55.75\n",
      "k: 19  accuracy: 55.95\n",
      "\n",
      "\n",
      "k: 21  accuracy: 52.6\n",
      "k: 21  accuracy: 54.949999999999996\n",
      "k: 21  accuracy: 53.0\n",
      "k: 21  accuracy: 53.0\n",
      "k: 21  accuracy: 53.65\n",
      "k: 21  accuracy: 54.400000000000006\n",
      "k: 21  accuracy: 56.89999999999999\n",
      "k: 21  accuracy: 55.15\n",
      "k: 21  accuracy: 55.900000000000006\n",
      "k: 21  accuracy: 55.60000000000001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = [11, 13, 15, 17, 19, 21]\n",
    "prediction_hamming = np.empty((len(k), 10, number_test))\n",
    "\n",
    "iteration = 0\n",
    "for k_num in k:\n",
    "    for i in range(10):\n",
    "        for j in range(number_test):\n",
    "            neareast_class = []\n",
    "            neareast_class = sample_raw_train_y[i][np.argsort(hamming_dists_matrix[i][j])][:k_num]\n",
    "            neareast_class = neareast_class.astype(int)\n",
    "            prediction_hamming[iteration][i][j] = np.argmax(np.bincount(neareast_class.reshape(k_num, )))\n",
    "    iteration = iteration + 1\n",
    "\n",
    "for k_iter in range(len(k)):\n",
    "    isAnswer_hamming = np.empty((10, 2000))\n",
    "    isAnswer_hamming = sample_raw_test_y - prediction_hamming[k_iter].reshape(10, number_test, 1)\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"k: \" + str(k[k_iter])+ \"  accuracy: \"+str((np.count_nonzero(isAnswer_hamming[i] == 0)/number_test)*100))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn 으로 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sk_data_feature = normalized\n",
    "sk_data_class = data_class\n",
    "np.putmask(sk_data_class, sk_data_class == 'satisfied', 1)\n",
    "np.putmask(sk_data_class, sk_data_class == 'unsatisfied', 0)\n",
    "\n",
    "sk_train_x, sk_test_x , sk_train_y, sk_test_y = train_test_split(sk_data_feature, sk_data_class, test_size = 0.1, random_state = 100)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier.fit(sk_train_x, sk_train_y)\n",
    "k_list = [1, 3, 5, 7, 9, 11, 21, 31, 101, 201, 301, 601, 901, 1001, 1501, 1901]\n",
    "#이렇게 돌리는데 11초\n",
    "accuracies = []\n",
    "for k in k_list:\n",
    "  classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "  classifier.fit(sk_train_x, sk_train_y)\n",
    "  accuracies.append(classifier.score(sk_test_x, sk_test_y))\n",
    "plt.plot(k_list, accuracies)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"test Accuracy\")\n",
    "plt.title(\"satisfaction accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting saving process..\n",
      "successfullt concatenated results...\n",
      "results saved to 20173709.csv\n",
      "successfully done.\n"
     ]
    }
   ],
   "source": [
    "#저장된 결과를 csv파일로 저장합니다.\n",
    "#3차원으로 저장이 되어있기 때문에 2차원으로 변환해줍니다.\n",
    "#이때, 정답의 값과 추정값을 붙여서 출력합니다.\n",
    "\n",
    "print(\"starting saving process..\")\n",
    "result_class_prediction = np.empty((number_test, 0), int)\n",
    "for i in range(10):\n",
    "    concatenated = np.concatenate((sample_test_y[i], prediction[0][i].reshape(number_test, 1)), axis = 1)\n",
    "    result_class_prediction = np.concatenate((result_class_prediction, concatenated), axis = 1)\n",
    "print(\"successfullt concatenated results...\")\n",
    "\n",
    "np.savetxt(\"20173709.csv\", result_class_prediction, fmt='%d', delimiter=',')\n",
    "print(\"results saved to 20173709.csv\")\n",
    "print(\"successfully done.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1aed0731b374a17b9f5237a21f75219259882e38811e96316e45347e29d5756"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
