{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_data = './satisfaction_data.csv'\n",
    "#data = np.genfromtxt(filename_data, encoding = 'ascii', names=('age', 'workclass', 'fnlwgt', 'educational_num', 'marital_status', 'hours_per_week', 'satisfaction'), delimiter =',', dtype = None)\n",
    "data_feature = np.loadtxt(filename_data, delimiter =',',usecols= (0,1,2,3,4,5), dtype=int)\n",
    "data_class = np.loadtxt(filename_data, delimiter =',',usecols= (6), dtype='str')\n",
    "number_data = data_feature.shape[0]\n",
    "\n",
    "#genfromtext를 전 영역에 대해서 쓰니까 string 값들이 nan으로 나온다..\n",
    "#여기서 nan이란 not a number 라는 뜻.\n",
    "#dtype을 float64로 가져와서 발생하는 현상.\n",
    "#https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=radii26omg&logNo=221051465120\n",
    "\n",
    "#print('number of data = ', number_data)\n",
    "#print(data_feature.shape)\n",
    "#print(data_feature[0].dtype)\n",
    "#print(data_class.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_col_0\n",
      "min:1.0\n",
      "max:99.0\n",
      "mean:43.22015\n",
      "var:140.24748397747882\n",
      "\n",
      "data_col_1\n",
      "min:0.0\n",
      "max:5.0\n",
      "mean:2.3586\n",
      "var:1.2923060399996893\n",
      "\n",
      "data_col_2\n",
      "min:0.0\n",
      "max:2.0\n",
      "mean:1.1708\n",
      "var:0.31852736000004944\n",
      "\n",
      "data_col_3\n",
      "min:13769.0\n",
      "max:1097453.0\n",
      "mean:184706.98085\n",
      "var:10226020824.74352\n",
      "\n",
      "data_col_4\n",
      "min:17.0\n",
      "max:90.0\n",
      "mean:39.4344\n",
      "var:165.8094966400004\n",
      "\n",
      "data_col_5\n",
      "min:1.0\n",
      "max:16.0\n",
      "mean:10.30435\n",
      "var:6.026421077499933\n",
      "\n",
      "[[1.000000e+00 9.900000e+01]\n",
      " [0.000000e+00 5.000000e+00]\n",
      " [0.000000e+00 2.000000e+00]\n",
      " [1.376900e+04 1.097453e+06]\n",
      " [1.700000e+01 9.000000e+01]\n",
      " [1.000000e+00 1.600000e+01]]\n"
     ]
    }
   ],
   "source": [
    "minmax = np.empty((6,2), float)\n",
    "\n",
    "for i in range(6):\n",
    "    print(\"data_col_\"+str(i))\n",
    "    minmax[i][0] = np.min(data_feature, axis=0)[i]\n",
    "    print(\"min:\"+str(minmax[i][0]))\n",
    "    minmax[i][1] = np.max(data_feature, axis=0)[i]\n",
    "    print(\"max:\"+str(minmax[i][1]))\n",
    "    print(\"mean:\"+str(np.mean(data_feature, axis=0)[i]))\n",
    "    print(\"var:\"+str(np.var(data_feature, axis=0)[i]))\n",
    "    print(\"\")\n",
    "print(minmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39795918 0.4        0.5        0.06745786 0.10958904 0.53333333]\n",
      " [0.39795918 0.4        0.5        0.22659188 0.50684932 0.6       ]\n",
      " [0.39795918 0.4        0.5        0.22427571 0.35616438 0.86666667]\n",
      " ...\n",
      " [0.39795918 0.4        0.5        0.15553796 0.20547945 0.26666667]\n",
      " [0.39795918 0.6        0.5        0.03829806 0.4109589  0.6       ]\n",
      " [0.5        0.8        0.5        0.04785066 0.24657534 0.8       ]]\n"
     ]
    }
   ],
   "source": [
    "# 거리를 구할 때 유클리드 거리 (l2 norm)으로 구할 예정\n",
    "# 한 요소가 너무 커버리면 그 요소에 다른게 trivial 해진다.\n",
    "# normalization을 해주자.\n",
    "normalized = np.empty((20000,6))\n",
    "#print(normalized.shape[1])\n",
    "for i in range(normalized.shape[1]):\n",
    "    normalized[:, i] = (data_feature[:, i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "print(normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# augment feature and class data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented = np.concatenate((normalized, data_class.reshape(20000, 1)), axis = 1)\n",
    "#print(data_augmented)\n",
    "#print(data_augmented)\n",
    "#print(data_augmented[0][6].dtype)\n",
    "\n",
    "#unsatisfied 는 0으로, satisfied는 1로 바꾼다.\n",
    "np.putmask(data_augmented, data_augmented == 'satisfied', 1)\n",
    "np.putmask(data_augmented, data_augmented == 'unsatisfied', 0)\n",
    "#print(data_augmented[0])\n",
    "#print(data_augmented[2])\n",
    "#print(data_augmented[0][0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "## train data set, test data set separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20000, 7)\n",
      "[[0.5        1.         0.         0.12738031 0.34246575 0.53333333]\n",
      " [0.44897959 0.4        0.         0.17630601 0.21917808 0.53333333]\n",
      " [0.44897959 0.4        0.         0.18466453 0.20547945 0.6       ]\n",
      " ...\n",
      " [0.42857143 0.4        0.         0.15645705 0.34246575 0.53333333]\n",
      " [0.44897959 0.4        0.5        0.1723113  0.1369863  0.2       ]\n",
      " [0.39795918 0.4        0.5        0.15907589 0.4109589  0.53333333]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#샘플 인덱스들의 배열\n",
    "#sample_train = np.empty((0,2000), int)\n",
    "\n",
    "#for i in range(10):\n",
    "#    sample_train = np.append(sample_train, np.random.choice(20000, 2000, replace=False).reshape(1, 2000), axis=0)\n",
    "#    print(sample_train[i])\n",
    "#print(sample_train.shape)\n",
    "\n",
    "\n",
    "#데이터의 총 개수는 20000개로, 1:9로 나누면 2000, 18000이다\n",
    "#훈련데이터에 사용할 데이터를 18000, 테스트에 사용할 데이터를 2000개로 설정하자.\n",
    "#0~19999의 숫자 중에서 2000개를 샘플링한다.\n",
    "\n",
    "\n",
    "#무작위로 배열하고 2000:18000으로 split하는게 나을 듯..\n",
    "#print(data_feature.shape)\n",
    "# sample_train_x = np.empty((10, 18000, 6), np.uint64)\n",
    "# sample_train_y = np.empty((10, 18000, 1), np.uint64)\n",
    "# sample_test_x = np.empty((10, 2000, 6), np.uint64)\n",
    "# sample_test_y = np.empty((10, 2000, 1), np.uint64)\n",
    "#data_feature_mixed = np.random.permutation(data_feature)\n",
    "#print(data_feature_mixed)\n",
    "\n",
    "sample_train_x = np.empty((10, 18000, 6))\n",
    "sample_train_y = np.empty((10, 18000, 1))\n",
    "sample_test_x = np.empty((10, 2000, 6))\n",
    "sample_test_y = np.empty((10, 2000, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    data_augmented_mixed = np.random.permutation(data_augmented).reshape(1, 20000, 7)\n",
    "    #print(data_augmented_mixed[0][0][6])\n",
    "    sample_train_x[i], sample_test_x[i] = data_augmented_mixed[0, 2000:, :6], data_augmented_mixed[0, :2000, :6]\n",
    "    sample_train_y[i], sample_test_y[i] = data_augmented_mixed[0, 2000:, 6].reshape(1, 18000, 1), data_augmented_mixed[0, :2000, 6].reshape(1, 2000, 1)\n",
    "print(data_augmented_mixed.shape)\n",
    "#print(sample_train.shape)\n",
    "#print(sample_test.shape)\n",
    "#print(sample_train)\n",
    "print(sample_train_x[0])\n",
    "#print(sample_test_x[0])\n",
    "print(sample_train_y[0])\n",
    "#print(sample_test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute distance > 2for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력으로 들어오는 feature에 대해서 각각의 요소에 대해 거리를 구한다. \n",
    "# feature에 들어있는 모든 요소는 정수형이기 때문에 거리를 구할 수 있다.\n",
    "\n",
    "number_train = sample_train_x.shape[1]\n",
    "number_test = sample_test_x.shape[1]\n",
    "euclid_dists = np.zeros((number_test, number_train))\n",
    "#print(number_train, number_test)\n",
    "#print(sample_train_x[0][0])\n",
    "#print(sample_test_x[0][0])\n",
    "#print(np.square(sample_train_x[0][0] - sample_test_x[0][0]))\n",
    "#print(np.sum(np.square(sample_train_x[0][0] - sample_test_x[0][0])))\n",
    "#print(np.sqrt(np.sum(np.square(sample_train_x[0][0] - sample_test_x[0][0]))))\n",
    "\n",
    "# RuntimeWarning: invalid value encountered in sqrt\n",
    "# 루트를 계산하는데 음수가 나오는 경우에 주로 발생\n",
    "# 설계 상 음수가 나올 수 없음.. 오버플로가 일어남\n",
    "\n",
    "#print(sample_test_x[0].shape)\n",
    "#print(sample_train_x[0].shape)\n",
    "\n",
    "# 바로 l2 norm을 계산하기에는 4번째 요소가 너무 큼.\n",
    "# >> overflow\n",
    "# 데이터타입을 np.uint64로 변경\n",
    "# 또는 normalization을 할 수도?\n",
    "\n",
    "#for문을 2중 루프로 돌리니 너무 느리다.\n",
    "#본인 컴퓨터 기준 샘플당 6분 6초\n",
    "#10개의 샘플을 돌리면 1시간.\n",
    "# for i in range(number_test):\n",
    "#     for j in range(number_train):\n",
    "#         euclid_dists[i, j] = np.sqrt(np.sum(np.square(sample_test_x[0][i] - sample_train_x[0][j])))\n",
    "# print(euclid_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute distance > matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2000, 18000)\n"
     ]
    }
   ],
   "source": [
    "#euclid_dist_matrix는\n",
    "#샘플마다\n",
    "#각 테스트케이스에 대해서 \n",
    "#모든 train set에 대한 거리를 저장한다.\n",
    "euclid_dists_matrix = np.zeros((10, number_test, number_train))\n",
    "#print(euclid_dists_matrix.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    test_matrix = np.sum(np.square(sample_test_x[i]), axis=1).reshape(number_test, 1)\n",
    "    train_matrix = np.sum(np.square(sample_train_x[i]), axis=1).reshape(1, number_train)\n",
    "    euclid_dists_matrix[i] = np.sqrt(test_matrix + train_matrix -2*np.dot(sample_test_x[i], sample_train_x[i].T))\n",
    "print(euclid_dists_matrix.shape)\n",
    "\n",
    "#print(np.sum(np.square(sample_test_x[0]), axis=1).reshape(number_test, 1).shape)\n",
    "# (2000, 1)\n",
    "#print(np.sum(np.square(sample_train_x[0]), axis=1).reshape(1, number_train).shape)\n",
    "# (1, 18000)\n",
    "#print(sample_test_x[0].shape)\n",
    "# (2000, 6)\n",
    "#print(sample_train_x[i].T.shape)\n",
    "# (6, 18000)\n",
    "\n",
    "#이렇게 계산하면 0.4초만에 된다.\n",
    "#10번하면 5.2초!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## difference between two calculated distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: 여기 뭔가 이상함.\n",
    "#print(np.sum(euclid_dists - euclid_dists_matrix[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제 참고자료에서 5라고 나옴.\n",
    "k = [5]\n",
    "prediction = np.empty((len(k), 10, number_test))\n",
    "#이렇게 실행하는데..\n",
    "#knn한 번 실행하는데 약 45초 걸림\n",
    "#k 가 47일 떄 55초 걸림,\n",
    "iteration = 0\n",
    "for k_num in k:\n",
    "    for i in range(10):\n",
    "        for j in range(number_test):\n",
    "            neareast_class = []\n",
    "            #print(sample_train_y.shape)\n",
    "            #print(np.argsort(euclid_dists_matrix[i]))\n",
    "            #print(np.argsort(euclid_dists_matrix[i]).shape)\n",
    "            \n",
    "            #argsort는 넘파이 행렬을 인풋으로 받는다.\n",
    "            #받은 행렬을 오름차순으로 정렬하여,\n",
    "            #정렬된 요소들의 인덱스를 반환한다.\n",
    "            #즉, np.argsort(euclid_dists_matrix[i][j]) 부분은\n",
    "            #i번째 샘플의 j번째 테스트케이스에 대해서 \n",
    "            #모든 값들을 정렬하고\n",
    "            #정렬된 요소들의 정렬되기 전 인덱스를 반환한다.\n",
    "            #즉, j번째 test_x와 가장 가까운 순서부터 먼 순서까지 (오름차순으로 정렬했으므로) \n",
    "            #train_x의 인덱스를 반환한다.\n",
    "            #여기서 k번째까지를 가져와 nearest class에 저장한다.\n",
    "            neareast_class = sample_train_y[i][np.argsort(euclid_dists_matrix[i][j])][:k_num]\n",
    "            #print(neareast_class)\n",
    "            #print(neareast_class.shape)\n",
    "            #print(neareast_class[0].dtype)\n",
    "\n",
    "            #저장 형식을 갖게 지정한다.\n",
    "            neareast_class = neareast_class.astype(int)\n",
    "            # print(neareast_class.shape)\n",
    "            # print(neareast_class)\n",
    "\n",
    "            #bincount란 non negative integer로 구성된 넘파이 어레이에서\n",
    "            #각각의 빈도수를 세는데 사용하는 메소드다.\n",
    "            #0부터 가장 큰 값까지 각각의 발생 빈도수를 체크한다.\n",
    "            #정답 클래스는 0(unsatisfied), 1(satisfied) 이므로\n",
    "            #[n m] (n, m은 0 이상의 정수)를 반환한다.\n",
    "            #n은 0인 값들의 개수, m은 1인 값들의 개수이다.\n",
    "            #argmax는 인풋으로 받은 행렬 중에서\n",
    "            #가장 값이 큰 인덱스를 반환한다.\n",
    "            #즉, n이 m보다 크다면 n의 인덱스, 0을 반환한다.\n",
    "            #이 인덱스는 결국 클래스를 나타내게 된다.\n",
    "            prediction[iteration][i][j] = np.argmax(np.bincount(neareast_class.reshape(k_num, )))\n",
    "    iteration = iteration + 1\n",
    "    #print(iteration)\n",
    "\n",
    "# print(euclid_dists_matrix[0].shape)\n",
    "# print(euclid_dists_matrix.shape)\n",
    "# print(sample_train_y[0].shape)\n",
    "# print(np.argsort(euclid_dists_matrix[0][0]))\n",
    "# print(sample_train_y[0][np.argsort(euclid_dists_matrix[0][0])][:k].shape)\n",
    "# print(neareast_class)\n",
    "# print(neareast_class[0])\n",
    "# print(neareast_class.shape)\n",
    "# print(prediction)\n",
    "# print(prediction.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare prediction and real class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 5  accuracy: 73.7\n",
      "k: 5  accuracy: 73.8\n",
      "k: 5  accuracy: 74.95\n",
      "k: 5  accuracy: 75.55\n",
      "k: 5  accuracy: 74.65\n",
      "k: 5  accuracy: 74.45\n",
      "k: 5  accuracy: 74.9\n",
      "k: 5  accuracy: 76.75\n",
      "k: 5  accuracy: 75.85\n",
      "k: 5  accuracy: 73.75\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(sample_test_y[0].shape) \n",
    "# (2000, 1)\n",
    "#print(prediction.reshape(number_test, 1).shape)\n",
    "# (2000, 1)\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "#     #print(sample_test_y[i].reshape(2000, ) - prediction[i])\n",
    "#     isAnswer = sample_test_y[i].reshape(2000, ) - prediction[i]\n",
    "#     #print(len(isAnswer[isAnswer == 0]))\n",
    "\n",
    "#     number_correct = len(isAnswer[isAnswer == 0])\n",
    "\n",
    "#     print(\"accuracy: \"+str((number_correct/number_test)*100))\n",
    "for k_iter in range(len(k)):\n",
    "    isAnswer = np.empty((10, 2000))\n",
    "    #isAnswer에는 정답 - 추정한 클래스 값이 들어가 있다. \n",
    "    #즉, 요소가 0일 경우 해당 인덱스는 정답이고, \n",
    "    #그 이외의 경우 오답이다.\n",
    "    isAnswer = sample_test_y - prediction[k_iter].reshape(10, number_test, 1)\n",
    "\n",
    "    #number_correct에는 각 샘플 별 0인 인덱스의 개수를 저장한다.\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"k: \" + str(k[k_iter])+ \"  accuracy: \"+str((np.count_nonzero(isAnswer[i] == 0)/number_test)*100))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "#print(prediction[0].shape)\n",
    "#print(sample_test_y[i].shape)\n",
    "#print(sample_test_y[i].reshape(2000,).shape)\n",
    "#print(sample_test_y[i].reshape(2000, ) - prediction[i])\n",
    "#TODO: accuracy를 올리려면? 해밍 거리밖에 없나\n",
    "#TODO: 결과 <학번>.csv로 만들기\n",
    "#TODO: 실행파일 만들기\n",
    "#TODO: 라이브러리 써서 만든 다음 결과 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute by hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2000, 18000)\n"
     ]
    }
   ],
   "source": [
    "#해밍 거리란 두 벡터간의 공통된 값의 수다.\n",
    "#비트간 해밍거리는 같아지기 위해서 바꿔야하는 비트의 값이 해밍거리가 된다.\n",
    "#즉, 해밍거리의 값이 커질 수록 유사도가 낮다고 할 수 있다. \n",
    "#해밍거리가 작다 = 유사도가 높다 = 가깝다.\n",
    "#비트간 해밍거리를 구하기위해서는\n",
    "#XOR연산을 한 후, \n",
    "#1의 개수를 세면 된다.\n",
    "#여기선 normalization이 필요없기떄문에 그대로 raw값을 사용한다.\n",
    "\n",
    "data_raw_augmented = np.concatenate((data_feature, data_class.reshape(20000, 1)), axis = 1)\n",
    "np.putmask(data_raw_augmented, data_raw_augmented == 'satisfied', 1)\n",
    "np.putmask(data_raw_augmented, data_raw_augmented == 'unsatisfied', 0)\n",
    "#print(data_raw_augmented)\n",
    "\n",
    "sample_raw_train_x = np.empty((10, 18000, 6))\n",
    "sample_raw_train_y = np.empty((10, 18000, 1))\n",
    "sample_raw_test_x = np.empty((10, 2000, 6))\n",
    "sample_raw_test_y = np.empty((10, 2000, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    data_raw_augmented_mixed = np.random.permutation(data_raw_augmented).reshape(1, 20000, 7)\n",
    "    #print(data_augmented_mixed[0][0][6])\n",
    "    sample_raw_train_x[i], sample_raw_test_x[i] = data_raw_augmented_mixed[0, 2000:, :6], data_raw_augmented_mixed[0, :2000, :6]\n",
    "    sample_raw_train_y[i], sample_raw_test_y[i] = data_raw_augmented_mixed[0, 2000:, 6].reshape(1, 18000, 1), data_raw_augmented_mixed[0, :2000, 6].reshape(1, 2000, 1)\n",
    "\n",
    "#메모리 초과방지를 위해 타입 지정\n",
    "subtracted_matrix = np.zeros((10, number_test, number_train, 6), int)\n",
    "subtracted_logical_xor = np.zeros((10, number_test, number_train, 6), bool)\n",
    "hamming_dists_matrix = np.zeros((10, number_test, number_train))\n",
    "#print(euclid_dists_matrix.shape)\n",
    "\n",
    "#해밍 거리로 변환\n",
    "#실행하는데,, 1분20초 걸림\n",
    "for i in range(10):\n",
    "    subtracted_matrix[i] = sample_raw_test_x[i].reshape(number_test, 1, 6) - sample_raw_train_x[i].reshape(1, number_train, 6)\n",
    "    subtracted_logical_xor[i] = np.logical_xor(subtracted_matrix[i], 0)\n",
    "    sameistrue = np.logical_not(subtracted_logical_xor[i])\n",
    "    hamming_dists_matrix[i] = sameistrue.sum(axis=2)\n",
    "print(hamming_dists_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 11  accuracy: 52.6\n",
      "k: 11  accuracy: 54.05\n",
      "k: 11  accuracy: 52.7\n",
      "k: 11  accuracy: 54.75\n",
      "k: 11  accuracy: 56.00000000000001\n",
      "k: 11  accuracy: 55.65\n",
      "k: 11  accuracy: 54.1\n",
      "k: 11  accuracy: 51.24999999999999\n",
      "k: 11  accuracy: 53.65\n",
      "k: 11  accuracy: 56.49999999999999\n",
      "\n",
      "\n",
      "k: 13  accuracy: 52.1\n",
      "k: 13  accuracy: 54.0\n",
      "k: 13  accuracy: 53.65\n",
      "k: 13  accuracy: 54.2\n",
      "k: 13  accuracy: 56.85\n",
      "k: 13  accuracy: 55.7\n",
      "k: 13  accuracy: 53.1\n",
      "k: 13  accuracy: 51.6\n",
      "k: 13  accuracy: 54.300000000000004\n",
      "k: 13  accuracy: 55.55\n",
      "\n",
      "\n",
      "k: 15  accuracy: 53.65\n",
      "k: 15  accuracy: 54.75\n",
      "k: 15  accuracy: 54.300000000000004\n",
      "k: 15  accuracy: 55.15\n",
      "k: 15  accuracy: 55.95\n",
      "k: 15  accuracy: 56.35\n",
      "k: 15  accuracy: 53.849999999999994\n",
      "k: 15  accuracy: 52.0\n",
      "k: 15  accuracy: 54.800000000000004\n",
      "k: 15  accuracy: 56.699999999999996\n",
      "\n",
      "\n",
      "k: 17  accuracy: 53.300000000000004\n",
      "k: 17  accuracy: 54.949999999999996\n",
      "k: 17  accuracy: 53.849999999999994\n",
      "k: 17  accuracy: 55.1\n",
      "k: 17  accuracy: 55.35\n",
      "k: 17  accuracy: 56.2\n",
      "k: 17  accuracy: 55.35\n",
      "k: 17  accuracy: 52.849999999999994\n",
      "k: 17  accuracy: 53.800000000000004\n",
      "k: 17  accuracy: 56.95\n",
      "\n",
      "\n",
      "k: 19  accuracy: 54.0\n",
      "k: 19  accuracy: 54.75\n",
      "k: 19  accuracy: 55.1\n",
      "k: 19  accuracy: 55.95\n",
      "k: 19  accuracy: 55.900000000000006\n",
      "k: 19  accuracy: 56.45\n",
      "k: 19  accuracy: 55.300000000000004\n",
      "k: 19  accuracy: 53.65\n",
      "k: 19  accuracy: 54.800000000000004\n",
      "k: 19  accuracy: 57.25\n",
      "\n",
      "\n",
      "k: 21  accuracy: 54.15\n",
      "k: 21  accuracy: 55.00000000000001\n",
      "k: 21  accuracy: 55.45\n",
      "k: 21  accuracy: 56.35\n",
      "k: 21  accuracy: 55.45\n",
      "k: 21  accuracy: 55.900000000000006\n",
      "k: 21  accuracy: 55.60000000000001\n",
      "k: 21  accuracy: 52.349999999999994\n",
      "k: 21  accuracy: 54.75\n",
      "k: 21  accuracy: 57.599999999999994\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = [11, 13, 15, 17, 19, 21]\n",
    "#이렇게 돌리는데 1분40초\n",
    "prediction_hamming = np.empty((len(k), 10, number_test))\n",
    "\n",
    "#knn한 번 실행하는데 약 45초 걸림\n",
    "#k 가 47일 떄 55초 걸림\n",
    "iteration = 0\n",
    "for k_num in k:\n",
    "    for i in range(10):\n",
    "        for j in range(number_test):\n",
    "            neareast_class = []\n",
    "            neareast_class = sample_raw_train_y[i][np.argsort(hamming_dists_matrix[i][j])][:k_num]\n",
    "            neareast_class = neareast_class.astype(int)\n",
    "            prediction_hamming[iteration][i][j] = np.argmax(np.bincount(neareast_class.reshape(k_num, )))\n",
    "    iteration = iteration + 1\n",
    "\n",
    "for k_iter in range(len(k)):\n",
    "    isAnswer_hamming = np.empty((10, 2000))\n",
    "    isAnswer_hamming = sample_raw_test_y - prediction_hamming[k_iter].reshape(10, number_test, 1)\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"k: \" + str(k[k_iter])+ \"  accuracy: \"+str((np.count_nonzero(isAnswer_hamming[i] == 0)/number_test)*100))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn 으로 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sk_data_feature = normalized\n",
    "sk_data_class = data_class\n",
    "np.putmask(sk_data_class, sk_data_class == 'satisfied', 1)\n",
    "np.putmask(sk_data_class, sk_data_class == 'unsatisfied', 0)\n",
    "\n",
    "sk_train_x, sk_test_x , sk_train_y, sk_test_y = train_test_split(sk_data_feature, sk_data_class, test_size = 0.1, random_state = 100)\n",
    "\n",
    "#print(len(sk_train_x))\n",
    "#print(len(sk_test_x))\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier.fit(sk_train_x, sk_train_y)\n",
    "#print(classifier.score(sk_test_x, sk_test_y))\n",
    "\n",
    "k_list = [1, 3, 5, 7, 9, 11, 21, 31, 101, 301, 601, 901, 1001, 1501, 1901]\n",
    "#이렇게 돌리는데 11초\n",
    "accuracies = []\n",
    "for k in k_list:\n",
    "  classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "  classifier.fit(sk_train_x, sk_train_y)\n",
    "  accuracies.append(classifier.score(sk_test_x, sk_test_y))\n",
    "plt.plot(k_list, accuracies)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"test Accuracy\")\n",
    "plt.title(\"satisfaction accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 2000)\n",
      "(2000, 20)\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [1. 1. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#print(prediction.shape)\n",
    "#np.savetxt(\"20173709.csv\", prediction[0][0], fmt='%d', delimiter=',')\n",
    "#prediction[0]에는\n",
    "#첫번째 k에 대해서\n",
    "#10개의 샘플들에 대한\n",
    "#각각의 테스트 데이터의 예측 결과를 반환.\n",
    "#print(prediction[0][0].reshape(number_test, 1).shape)\n",
    "#print(sample_test_y[0].shape)#\n",
    "\n",
    "#3차원으로 저장이 되어있기 때문에 2차원으로 펼친다.\n",
    "result_class_prediction = np.empty((number_test, 0), int)\n",
    "for i in range(10):\n",
    "    concatenated = np.concatenate((sample_test_y[i], prediction[0][i].reshape(number_test, 1)), axis = 1)\n",
    "    #print(concatenated.shape)\n",
    "    result_class_prediction = np.concatenate((result_class_prediction, concatenated), axis = 1)\n",
    "\n",
    "#print(result_class_prediction.shape)\n",
    "#print(result_class_prediction)\n",
    "\n",
    "np.savetxt(\"20173709.csv\", result_class_prediction, fmt='%d', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1aed0731b374a17b9f5237a21f75219259882e38811e96316e45347e29d5756"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
