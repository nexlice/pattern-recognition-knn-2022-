{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_data = './satisfaction_data.csv'\n",
    "#data = np.genfromtxt(filename_data, encoding = 'ascii', names=('age', 'workclass', 'fnlwgt', 'educational_num', 'marital_status', 'hours_per_week', 'satisfaction'), delimiter =',', dtype = None)\n",
    "data_feature = np.loadtxt(filename_data, delimiter =',',usecols= (0,1,2,3,4,5), dtype=int)\n",
    "data_class = np.loadtxt(filename_data, delimiter =',',usecols= (6), dtype='str')\n",
    "number_data = data_feature.shape[0]\n",
    "\n",
    "#genfromtext를 전 영역에 대해서 쓰니까 string 값들이 nan으로 나온다..\n",
    "#여기서 nan이란 not a number 라는 뜻.\n",
    "#dtype을 float64로 가져와서 발생하는 현상.\n",
    "#https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=radii26omg&logNo=221051465120\n",
    "\n",
    "#print('number of data = ', number_data)\n",
    "#print(data_feature.shape)\n",
    "#print(data_feature[0].dtype)\n",
    "#print(data_class.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = np.empty((6,2), float)\n",
    "\n",
    "for i in range(6):\n",
    "    print(\"data_col_\"+str(i))\n",
    "    minmax[i][0] = np.min(data_feature, axis=0)[i]\n",
    "    print(\"min:\"+str(minmax[i][0]))\n",
    "    minmax[i][1] = np.max(data_feature, axis=0)[i]\n",
    "    print(\"max:\"+str(minmax[i][1]))\n",
    "    print(\"mean:\"+str(np.mean(data_feature, axis=0)[i]))\n",
    "    print(\"var:\"+str(np.var(data_feature, axis=0)[i]))\n",
    "    print(\"\")\n",
    "print(minmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리를 구할 때 유클리드 거리 (l2 norm)으로 구할 예정\n",
    "# 한 요소가 너무 커버리면 그 요소에 다른게 trivial 해진다.\n",
    "# normalization을 해주자.\n",
    "normalized = np.empty((20000,6))\n",
    "#print(normalized.shape[1])\n",
    "for i in range(normalized.shape[1]):\n",
    "    normalized[:, i] = (data_feature[:, i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "print(normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# augment feature and class data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented = np.concatenate((normalized, data_class.reshape(20000, 1)), axis = 1)\n",
    "#print(data_augmented)\n",
    "#print(data_augmented)\n",
    "#print(data_augmented[0][6].dtype)\n",
    "\n",
    "#unsatisfied 는 0으로, satisfied는 1로 바꾼다.\n",
    "np.putmask(data_augmented, data_augmented == 'satisfied', 1)\n",
    "np.putmask(data_augmented, data_augmented == 'unsatisfied', 0)\n",
    "#print(data_augmented[0])\n",
    "#print(data_augmented[2])\n",
    "#print(data_augmented[0][0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "## train data set, test data set separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#샘플 인덱스들의 배열\n",
    "#sample_train = np.empty((0,2000), int)\n",
    "\n",
    "#for i in range(10):\n",
    "#    sample_train = np.append(sample_train, np.random.choice(20000, 2000, replace=False).reshape(1, 2000), axis=0)\n",
    "#    print(sample_train[i])\n",
    "#print(sample_train.shape)\n",
    "\n",
    "\n",
    "#데이터의 총 개수는 20000개로, 1:9로 나누면 2000, 18000이다\n",
    "#훈련데이터에 사용할 데이터를 18000, 테스트에 사용할 데이터를 2000개로 설정하자.\n",
    "#0~19999의 숫자 중에서 2000개를 샘플링한다.\n",
    "\n",
    "\n",
    "#무작위로 배열하고 2000:18000으로 split하는게 나을 듯..\n",
    "#print(data_feature.shape)\n",
    "# sample_train_x = np.empty((10, 18000, 6), np.uint64)\n",
    "# sample_train_y = np.empty((10, 18000, 1), np.uint64)\n",
    "# sample_test_x = np.empty((10, 2000, 6), np.uint64)\n",
    "# sample_test_y = np.empty((10, 2000, 1), np.uint64)\n",
    "#data_feature_mixed = np.random.permutation(data_feature)\n",
    "#print(data_feature_mixed)\n",
    "\n",
    "sample_train_x = np.empty((10, 18000, 6))\n",
    "sample_train_y = np.empty((10, 18000, 1))\n",
    "sample_test_x = np.empty((10, 2000, 6))\n",
    "sample_test_y = np.empty((10, 2000, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    data_augmented_mixed = np.random.permutation(data_augmented).reshape(1, 20000, 7)\n",
    "    #print(data_augmented_mixed[0][0][6])\n",
    "    sample_train_x[i], sample_test_x[i] = data_augmented_mixed[0, 2000:, :6], data_augmented_mixed[0, :2000, :6]\n",
    "    sample_train_y[i], sample_test_y[i] = data_augmented_mixed[0, 2000:, 6].reshape(1, 18000, 1), data_augmented_mixed[0, :2000, 6].reshape(1, 2000, 1)\n",
    "print(data_augmented_mixed.shape)\n",
    "#print(sample_train.shape)\n",
    "#print(sample_test.shape)\n",
    "#print(sample_train)\n",
    "print(sample_train_x[0])\n",
    "#print(sample_test_x[0])\n",
    "print(sample_train_y[0])\n",
    "#print(sample_test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute distance > 2for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력으로 들어오는 feature에 대해서 각각의 요소에 대해 거리를 구한다. \n",
    "# feature에 들어있는 모든 요소는 정수형이기 때문에 거리를 구할 수 있다.\n",
    "\n",
    "number_train = sample_train_x.shape[1]\n",
    "number_test = sample_test_x.shape[1]\n",
    "euclid_dists = np.zeros((number_test, number_train))\n",
    "#print(number_train, number_test)\n",
    "#print(sample_train_x[0][0])\n",
    "#print(sample_test_x[0][0])\n",
    "#print(np.square(sample_train_x[0][0] - sample_test_x[0][0]))\n",
    "#print(np.sum(np.square(sample_train_x[0][0] - sample_test_x[0][0])))\n",
    "#print(np.sqrt(np.sum(np.square(sample_train_x[0][0] - sample_test_x[0][0]))))\n",
    "\n",
    "# RuntimeWarning: invalid value encountered in sqrt\n",
    "# 루트를 계산하는데 음수가 나오는 경우에 주로 발생\n",
    "# 설계 상 음수가 나올 수 없음.. 오버플로가 일어남\n",
    "\n",
    "#print(sample_test_x[0].shape)\n",
    "#print(sample_train_x[0].shape)\n",
    "\n",
    "# 바로 l2 norm을 계산하기에는 4번째 요소가 너무 큼.\n",
    "# >> overflow\n",
    "# 데이터타입을 np.uint64로 변경\n",
    "# 또는 normalization을 할 수도?\n",
    "\n",
    "#for문을 2중 루프로 돌리니 너무 느리다.\n",
    "#본인 컴퓨터 기준 샘플당 6분 6초\n",
    "#10개의 샘플을 돌리면 1시간.\n",
    "# for i in range(number_test):\n",
    "#     for j in range(number_train):\n",
    "#         euclid_dists[i, j] = np.sqrt(np.sum(np.square(sample_test_x[0][i] - sample_train_x[0][j])))\n",
    "# print(euclid_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute distance > matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#euclid_dist_matrix는\n",
    "#샘플마다\n",
    "#각 테스트케이스에 대해서 \n",
    "#모든 train set에 대한 거리를 저장한다.\n",
    "euclid_dists_matrix = np.zeros((10, number_test, number_train))\n",
    "#print(euclid_dists_matrix.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    test_matrix = np.sum(np.square(sample_test_x[i]), axis=1).reshape(number_test, 1)\n",
    "    train_matrix = np.sum(np.square(sample_train_x[i]), axis=1).reshape(1, number_train)\n",
    "    euclid_dists_matrix[i] = np.sqrt(test_matrix + train_matrix -2*np.dot(sample_test_x[i], sample_train_x[i].T))\n",
    "print(euclid_dists_matrix.shape)\n",
    "\n",
    "#print(np.sum(np.square(sample_test_x[0]), axis=1).reshape(number_test, 1).shape)\n",
    "# (2000, 1)\n",
    "#print(np.sum(np.square(sample_train_x[0]), axis=1).reshape(1, number_train).shape)\n",
    "# (1, 18000)\n",
    "#print(sample_test_x[0].shape)\n",
    "# (2000, 6)\n",
    "#print(sample_train_x[i].T.shape)\n",
    "# (6, 18000)\n",
    "\n",
    "#이렇게 계산하면 0.4초만에 된다.\n",
    "#10번하면 5.2초!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## difference between two calculated distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: 여기 뭔가 이상함.\n",
    "#print(np.sum(euclid_dists - euclid_dists_matrix[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제 참고자료에서 5라고 나옴.\n",
    "# 우선 4~10으로 해보자.\n",
    "k = [47]\n",
    "prediction = np.empty((len(k), 10, number_test))\n",
    "\n",
    "#knn한 번 실행하는데 약 45초 걸림\n",
    "#k 가 47일 떄 55초 걸림\n",
    "iteration = 0\n",
    "for k_num in k:\n",
    "    for i in range(10):\n",
    "        for j in range(number_test):\n",
    "            neareast_class = []\n",
    "            #print(sample_train_y.shape)\n",
    "            #print(np.argsort(euclid_dists_matrix[i]))\n",
    "            #print(np.argsort(euclid_dists_matrix[i]).shape)\n",
    "            \n",
    "            #argsort는 넘파이 행렬을 인풋으로 받는다.\n",
    "            #받은 행렬을 오름차순으로 정렬하여,\n",
    "            #정렬된 요소들의 인덱스를 반환한다.\n",
    "            #즉, np.argsort(euclid_dists_matrix[i][j]) 부분은\n",
    "            #i번째 샘플의 j번째 테스트케이스에 대해서 \n",
    "            #모든 값들을 정렬하고\n",
    "            #정렬된 요소들의 정렬되기 전 인덱스를 반환한다.\n",
    "            #즉, j번째 test_x와 가장 가까운 순서부터 먼 순서까지 (오름차순으로 정렬했으므로) \n",
    "            #train_x의 인덱스를 반환한다.\n",
    "            #여기서 k번째까지를 가져와 nearest class에 저장한다.\n",
    "            neareast_class = sample_train_y[i][np.argsort(euclid_dists_matrix[i][j])][:k_num]\n",
    "            #print(neareast_class)\n",
    "            #print(neareast_class.shape)\n",
    "            #print(neareast_class[0].dtype)\n",
    "\n",
    "            #저장 형식을 갖게 지정한다.\n",
    "            neareast_class = neareast_class.astype(int)\n",
    "            # print(neareast_class.shape)\n",
    "            # print(neareast_class)\n",
    "\n",
    "            #bincount란 non negative integer로 구성된 넘파이 어레이에서\n",
    "            #각각의 빈도수를 세는데 사용하는 메소드다.\n",
    "            #0부터 가장 큰 값까지 각각의 발생 빈도수를 체크한다.\n",
    "            #정답 클래스는 0(unsatisfied), 1(satisfied) 이므로\n",
    "            #[n m] (n, m은 0 이상의 정수)를 반환한다.\n",
    "            #n은 0인 값들의 개수, m은 1인 값들의 개수이다.\n",
    "            #argmax는 인풋으로 받은 행렬 중에서\n",
    "            #가장 값이 큰 인덱스를 반환한다.\n",
    "            #즉, n이 m보다 크다면 n의 인덱스, 0을 반환한다.\n",
    "            #이 인덱스는 결국 클래스를 나타내게 된다.\n",
    "            prediction[iteration][i][j] = np.argmax(np.bincount(neareast_class.reshape(k_num, )))\n",
    "    iteration = iteration + 1\n",
    "    #print(iteration)\n",
    "\n",
    "# print(euclid_dists_matrix[0].shape)\n",
    "# print(euclid_dists_matrix.shape)\n",
    "# print(sample_train_y[0].shape)\n",
    "# print(np.argsort(euclid_dists_matrix[0][0]))\n",
    "# print(sample_train_y[0][np.argsort(euclid_dists_matrix[0][0])][:k].shape)\n",
    "# print(neareast_class)\n",
    "# print(neareast_class[0])\n",
    "# print(neareast_class.shape)\n",
    "# print(prediction)\n",
    "# print(prediction.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare prediction and real class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sample_test_y[0].shape) \n",
    "# (2000, 1)\n",
    "#print(prediction.reshape(number_test, 1).shape)\n",
    "# (2000, 1)\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "#     #print(sample_test_y[i].reshape(2000, ) - prediction[i])\n",
    "#     isAnswer = sample_test_y[i].reshape(2000, ) - prediction[i]\n",
    "#     #print(len(isAnswer[isAnswer == 0]))\n",
    "\n",
    "#     number_correct = len(isAnswer[isAnswer == 0])\n",
    "\n",
    "#     print(\"accuracy: \"+str((number_correct/number_test)*100))\n",
    "for k_iter in range(len(k)):\n",
    "    isAnswer = np.empty((10, 2000))\n",
    "    #isAnswer에는 정답 - 추정한 클래스 값이 들어가 있다. \n",
    "    #즉, 요소가 0일 경우 해당 인덱스는 정답이고, \n",
    "    #그 이외의 경우 오답이다.\n",
    "    isAnswer = sample_test_y - prediction[k_iter].reshape(10, number_test, 1)\n",
    "\n",
    "    #number_correct에는 각 샘플 별 0인 인덱스의 개수를 저장한다.\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"k: \" + str(k[k_iter])+ \"  accuracy: \"+str((np.count_nonzero(isAnswer[i] == 0)/number_test)*100))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "#print(prediction[0].shape)\n",
    "#print(sample_test_y[i].shape)\n",
    "#print(sample_test_y[i].reshape(2000,).shape)\n",
    "#print(sample_test_y[i].reshape(2000, ) - prediction[i])\n",
    "#TODO: accuracy를 올리려면? 해밍 거리밖에 없나\n",
    "#TODO: 결과 <학번>.csv로 만들기\n",
    "#TODO: 실행파일 만들기\n",
    "#TODO: 라이브러리 써서 만든 다음 결과 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute by hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2000, 18000)\n"
     ]
    }
   ],
   "source": [
    "#해밍 거리란 두 벡터간의 공통된 값의 수다.\n",
    "#비트간 해밍거리는 같아지기 위해서 바꿔야하는 비트의 값이 해밍거리가 된다.\n",
    "#즉, 해밍거리의 값이 커질 수록 유사도가 낮다고 할 수 있다. \n",
    "#해밍거리가 작다 = 유사도가 높다 = 가깝다.\n",
    "#비트간 해밍거리를 구하기위해서는\n",
    "#XOR연산을 한 후, \n",
    "#1의 개수를 세면 된다.\n",
    "#여기선 normalization이 필요없기떄문에 그대로 raw값을 사용한다.\n",
    "\n",
    "data_raw_augmented = np.concatenate((data_feature, data_class.reshape(20000, 1)), axis = 1)\n",
    "np.putmask(data_raw_augmented, data_raw_augmented == 'satisfied', 1)\n",
    "np.putmask(data_raw_augmented, data_raw_augmented == 'unsatisfied', 0)\n",
    "#print(data_raw_augmented)\n",
    "\n",
    "sample_raw_train_x = np.empty((10, 18000, 6))\n",
    "sample_raw_train_y = np.empty((10, 18000, 1))\n",
    "sample_raw_test_x = np.empty((10, 2000, 6))\n",
    "sample_raw_test_y = np.empty((10, 2000, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    data_raw_augmented_mixed = np.random.permutation(data_raw_augmented).reshape(1, 20000, 7)\n",
    "    #print(data_augmented_mixed[0][0][6])\n",
    "    sample_raw_train_x[i], sample_raw_test_x[i] = data_raw_augmented_mixed[0, 2000:, :6], data_raw_augmented_mixed[0, :2000, :6]\n",
    "    sample_raw_train_y[i], sample_raw_test_y[i] = data_raw_augmented_mixed[0, 2000:, 6].reshape(1, 18000, 1), data_raw_augmented_mixed[0, :2000, 6].reshape(1, 2000, 1)\n",
    "\n",
    "#메모리 초과방지를 위해 타입 지정\n",
    "subtracted_matrix = np.zeros((10, number_test, number_train, 6), int)\n",
    "subtracted_logical_xor = np.zeros((10, number_test, number_train, 6), bool)\n",
    "hamming_dists_matrix = np.zeros((10, number_test, number_train))\n",
    "#print(euclid_dists_matrix.shape)\n",
    "\n",
    "#해밍 거리로 변환\n",
    "#실행하는데,, 1분20초 걸림\n",
    "for i in range(10):\n",
    "    subtracted_matrix[i] = sample_raw_test_x[i].reshape(number_test, 1, 6) - sample_raw_train_x[i].reshape(1, number_train, 6)\n",
    "    subtracted_logical_xor[i] = np.logical_xor(subtracted_matrix[i], 0)\n",
    "    sameistrue = np.logical_not(subtracted_logical_xor[i])\n",
    "    hamming_dists_matrix[i] = sameistrue.sum(axis=2)\n",
    "print(hamming_dists_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 11  accuracy: 54.449999999999996\n",
      "k: 11  accuracy: 52.15\n",
      "k: 11  accuracy: 54.7\n",
      "k: 11  accuracy: 56.45\n",
      "k: 11  accuracy: 54.400000000000006\n",
      "k: 11  accuracy: 54.800000000000004\n",
      "k: 11  accuracy: 57.15\n",
      "k: 11  accuracy: 56.39999999999999\n",
      "k: 11  accuracy: 56.00000000000001\n",
      "k: 11  accuracy: 53.849999999999994\n",
      "\n",
      "\n",
      "k: 13  accuracy: 53.800000000000004\n",
      "k: 13  accuracy: 52.400000000000006\n",
      "k: 13  accuracy: 55.25\n",
      "k: 13  accuracy: 56.35\n",
      "k: 13  accuracy: 54.65\n",
      "k: 13  accuracy: 54.75\n",
      "k: 13  accuracy: 57.9\n",
      "k: 13  accuracy: 56.55\n",
      "k: 13  accuracy: 55.35\n",
      "k: 13  accuracy: 53.6\n",
      "\n",
      "\n",
      "k: 15  accuracy: 54.2\n",
      "k: 15  accuracy: 52.0\n",
      "k: 15  accuracy: 55.75\n",
      "k: 15  accuracy: 56.25\n",
      "k: 15  accuracy: 54.300000000000004\n",
      "k: 15  accuracy: 55.50000000000001\n",
      "k: 15  accuracy: 57.45\n",
      "k: 15  accuracy: 56.599999999999994\n",
      "k: 15  accuracy: 55.400000000000006\n",
      "k: 15  accuracy: 53.65\n",
      "\n",
      "\n",
      "k: 17  accuracy: 54.25\n",
      "k: 17  accuracy: 52.0\n",
      "k: 17  accuracy: 56.35\n",
      "k: 17  accuracy: 55.95\n",
      "k: 17  accuracy: 54.7\n",
      "k: 17  accuracy: 55.85\n",
      "k: 17  accuracy: 56.8\n",
      "k: 17  accuracy: 56.2\n",
      "k: 17  accuracy: 55.50000000000001\n",
      "k: 17  accuracy: 53.949999999999996\n",
      "\n",
      "\n",
      "k: 19  accuracy: 54.35\n",
      "k: 19  accuracy: 52.7\n",
      "k: 19  accuracy: 55.65\n",
      "k: 19  accuracy: 56.39999999999999\n",
      "k: 19  accuracy: 54.55\n",
      "k: 19  accuracy: 55.60000000000001\n",
      "k: 19  accuracy: 57.45\n",
      "k: 19  accuracy: 55.900000000000006\n",
      "k: 19  accuracy: 56.85\n",
      "k: 19  accuracy: 54.0\n",
      "\n",
      "\n",
      "k: 21  accuracy: 55.00000000000001\n",
      "k: 21  accuracy: 52.65\n",
      "k: 21  accuracy: 56.35\n",
      "k: 21  accuracy: 56.45\n",
      "k: 21  accuracy: 53.449999999999996\n",
      "k: 21  accuracy: 55.95\n",
      "k: 21  accuracy: 57.05\n",
      "k: 21  accuracy: 55.55\n",
      "k: 21  accuracy: 55.60000000000001\n",
      "k: 21  accuracy: 53.449999999999996\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = [11, 13, 15, 17, 19, 21]\n",
    "#이렇게 돌리는데 1분40초\n",
    "prediction_hamming = np.empty((len(k), 10, number_test))\n",
    "\n",
    "#knn한 번 실행하는데 약 45초 걸림\n",
    "#k 가 47일 떄 55초 걸림\n",
    "iteration = 0\n",
    "for k_num in k:\n",
    "    for i in range(10):\n",
    "        for j in range(number_test):\n",
    "            neareast_class = []\n",
    "            neareast_class = sample_raw_train_y[i][np.argsort(hamming_dists_matrix[i][j])][:k_num]\n",
    "            neareast_class = neareast_class.astype(int)\n",
    "            prediction_hamming[iteration][i][j] = np.argmax(np.bincount(neareast_class.reshape(k_num, )))\n",
    "    iteration = iteration + 1\n",
    "\n",
    "for k_iter in range(len(k)):\n",
    "    isAnswer_hamming = np.empty((10, 2000))\n",
    "    isAnswer_hamming = sample_raw_test_y - prediction_hamming[k_iter].reshape(10, number_test, 1)\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"k: \" + str(k[k_iter])+ \"  accuracy: \"+str((np.count_nonzero(isAnswer_hamming[i] == 0)/number_test)*100))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1aed0731b374a17b9f5237a21f75219259882e38811e96316e45347e29d5756"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
