{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn classifier 20173709\n",
      "The whole process takes about 35 seconds.\n",
      "starting loading data...\n",
      "successfully loaded data.\n",
      "number of data = 20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"knn classifier 20173709\")\n",
    "print(\"The whole process takes about 35 seconds.\")\n",
    "\n",
    "print(\"starting loading data...\")\n",
    "#같은 디렉토리 내에 있는 csv파일을 탐색합니다.\n",
    "filename_data = './satisfaction_data.csv'\n",
    "\n",
    "#0~5번째 열은 feature로, 6번째 열은 class데이터로 저장합니다.\n",
    "data_feature = np.loadtxt(filename_data, delimiter =',',usecols= (0,1,2,3,4,5), dtype=int)\n",
    "data_class = np.loadtxt(filename_data, delimiter =',',usecols= (6), dtype='str')\n",
    "number_data = data_feature.shape[0]\n",
    "\n",
    "print(\"successfully loaded data.\")\n",
    "print(\"number of data = \" + str(number_data))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data inspection\n",
      "data_col_0\n",
      "min:1.0\n",
      "max:99.0\n",
      "mean:43.22015\n",
      "var:140.24748397747882\n",
      "\n",
      "data_col_1\n",
      "min:0.0\n",
      "max:5.0\n",
      "mean:2.3586\n",
      "var:1.2923060399996893\n",
      "\n",
      "data_col_2\n",
      "min:0.0\n",
      "max:2.0\n",
      "mean:1.1708\n",
      "var:0.31852736000004944\n",
      "\n",
      "data_col_3\n",
      "min:13769.0\n",
      "max:1097453.0\n",
      "mean:184706.98085\n",
      "var:10226020824.74352\n",
      "\n",
      "data_col_4\n",
      "min:17.0\n",
      "max:90.0\n",
      "mean:39.4344\n",
      "var:165.8094966400004\n",
      "\n",
      "data_col_5\n",
      "min:1.0\n",
      "max:16.0\n",
      "mean:10.30435\n",
      "var:6.026421077499933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#추후 normalization을 위한 minmax를 저장합니다.\n",
    "#그리고 데이터의 전체적인 분포를 가늠하기위해\n",
    "#각 열마다, 즉, 각 파라미터마다 최소, 최대, 평균, 분산을 출력합니다.\n",
    "\n",
    "print(\"data inspection\")\n",
    "minmax = np.empty((6,2), float)\n",
    "\n",
    "for i in range(6):\n",
    "    print(\"data_col_\"+str(i))\n",
    "    minmax[i][0] = np.min(data_feature, axis=0)[i]\n",
    "    print(\"min:\"+str(minmax[i][0]))\n",
    "    minmax[i][1] = np.max(data_feature, axis=0)[i]\n",
    "    print(\"max:\"+str(minmax[i][1]))\n",
    "    print(\"mean:\"+str(np.mean(data_feature, axis=0)[i]))\n",
    "    print(\"var:\"+str(np.var(data_feature, axis=0)[i]))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting normalization...\n",
      "[[0.39795918 0.4        0.5        0.06745786 0.10958904 0.53333333]\n",
      " [0.39795918 0.4        0.5        0.22659188 0.50684932 0.6       ]\n",
      " [0.39795918 0.4        0.5        0.22427571 0.35616438 0.86666667]\n",
      " ...\n",
      " [0.39795918 0.4        0.5        0.15553796 0.20547945 0.26666667]\n",
      " [0.39795918 0.6        0.5        0.03829806 0.4109589  0.6       ]\n",
      " [0.5        0.8        0.5        0.04785066 0.24657534 0.8       ]]\n",
      "data is normalized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 거리를 구할 때 유클리드 거리 (l2 norm)으로 구합니다.\n",
    "# 한 요소의 범위가 너무 크다면, 그 feature때문에 다른 값들이 trivial 해집니다.\n",
    "# 데이터의 분포 모두 최소가 0, 최대가 1이 되도록 normalization을 해줍니다.\n",
    "print(\"starting normalization...\")\n",
    "normalized = np.empty((20000,6))\n",
    "#print(normalized.shape[1])\n",
    "for i in range(normalized.shape[1]):\n",
    "    normalized[:, i] = (data_feature[:, i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "print(normalized)\n",
    "print(\"data is normalized.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# augment feature and class data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터를 섞을 때 feature와 class가 함께 이동하도록 데이터를 합쳐줍니다.\n",
    "data_augmented = np.concatenate((normalized, data_class.reshape(20000, 1)), axis = 1)\n",
    "\n",
    "#추후 계산의 편의를 위해 unsatisfied 는 0으로, satisfied는 1로 바꿉니다.\n",
    "np.putmask(data_augmented, data_augmented == 'satisfied', 1)\n",
    "np.putmask(data_augmented, data_augmented == 'unsatisfied', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "## train data set, test data set separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting sampling data...\n",
      "sample_train_x : (10, 18000, 6)\n",
      "sample_train_y : (10, 18000, 1)\n",
      "sample_test_x : (10, 2000, 6)\n",
      "sample_test_y : (10, 2000, 1)\n",
      "successfully sampled data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터의 총 개수는 20000개로, 1:9로 나누면 2000, 18000입니다.\n",
    "#훈련데이터에 사용할 데이터를 18000, 테스트에 사용할 데이터를 2000개로 설정합니다.\n",
    "#0~19999의 숫자 중에서 2000개를 샘플링한다.\n",
    "\n",
    "print(\"starting sampling data...\")\n",
    "\n",
    "sample_train_x = np.empty((10, 18000, 6))\n",
    "sample_train_y = np.empty((10, 18000, 1))\n",
    "sample_test_x = np.empty((10, 2000, 6))\n",
    "sample_test_y = np.empty((10, 2000, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    data_augmented_mixed = np.random.permutation(data_augmented).reshape(1, 20000, 7)\n",
    "    sample_train_x[i], sample_test_x[i] = data_augmented_mixed[0, 2000:, :6], data_augmented_mixed[0, :2000, :6]\n",
    "    sample_train_y[i], sample_test_y[i] = data_augmented_mixed[0, 2000:, 6].reshape(1, 18000, 1), data_augmented_mixed[0, :2000, 6].reshape(1, 2000, 1)\n",
    "print(\"sample_train_x : \" +str(sample_train_x.shape))\n",
    "print(\"sample_train_y : \" +str(sample_train_y.shape))\n",
    "print(\"sample_test_x : \" +str(sample_test_x.shape))\n",
    "print(\"sample_test_y : \" +str(sample_test_y.shape))\n",
    "print(\"successfully sampled data.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute distance > matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting calculating distance by matrix...\n",
      "(10, 2000, 18000)\n",
      "successfully done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#euclid_dist_matrix에는, \n",
    "#샘플마다 각 test_x에 대해서 모든 train_x에 대한 거리를 저장한다.\n",
    "\n",
    "print(\"starting calculating distance by matrix...\") \n",
    "number_train = sample_train_x.shape[1]\n",
    "number_test = sample_test_x.shape[1]\n",
    "euclid_dists_matrix = np.zeros((10, number_test, number_train))\n",
    "for i in range(10):\n",
    "    test_matrix = np.sum(np.square(sample_test_x[i]), axis=1).reshape(number_test, 1)\n",
    "    train_matrix = np.sum(np.square(sample_train_x[i]), axis=1).reshape(1, number_train)\n",
    "    euclid_dists_matrix[i] = np.sqrt(test_matrix + train_matrix -2*np.dot(sample_test_x[i], sample_train_x[i].T))\n",
    "print(euclid_dists_matrix.shape)\n",
    "print(\"successfully done.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting prediction for 10 data sets...\n",
      "prediction : (10, 2000)\n",
      "successfully done.\n"
     ]
    }
   ],
   "source": [
    "# k 로 지정한 수를 리스트로 저장해주면, 각 k에 대해서 연산합니다.\n",
    "# 앞서서 최적의 k 에 대해서 논의했으므로, 지금은 하나의 k에 대해서만 계산합니다.\n",
    "print(\"starting prediction for 10 data sets...\")\n",
    "k = 101\n",
    "prediction = np.empty((10, number_test))\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(number_test):\n",
    "        neareast_class = []\n",
    "            \n",
    "        #argsort는 넘파이 행렬을 인풋으로 받습니다.\n",
    "        #받은 행렬을 오름차순으로 정렬하여,\n",
    "        #정렬된 요소들의 인덱스를 반환합니다..\n",
    "\n",
    "        #즉, np.argsort(euclid_dists_matrix[i][j]) 부분은\n",
    "        #i번째 샘플의 j번째 테스트케이스에 대해서 모든 값들을 정렬하고,\n",
    "        #정렬된 요소들의 정렬되기 전 인덱스를 반환합니다.\n",
    "        #즉, j번째 test_x와 가장 가까운 순서부터 먼 순서까지 (오름차순으로 정렬했으므로) \n",
    "        #train_x의 인덱스를 반환합니다.\n",
    "        #여기서 k번째까지를 가져와 nearest class에 저장합니다.\n",
    "        neareast_class = sample_train_y[i][np.argsort(euclid_dists_matrix[i][j])][:k]\n",
    "\n",
    "        #저장 형식을 갖게 지정한다.\n",
    "        neareast_class = neareast_class.astype(int)\n",
    "\n",
    "        #bincount란 non negative integer로 구성된 넘파이 배열에서\n",
    "        #각각의 빈도수를 세는데 사용하는 메소드입니다.\n",
    "        #0부터 가장 큰 값까지 각각의 발생 빈도수를 체크합니다.\n",
    "        #정답 클래스는 0(unsatisfied), 1(satisfied) 이므로\n",
    "        #[n m] (n, m은 0 이상의 정수)를 반환합니다.\n",
    "        #n은 0인 값들의 개수, m은 1인 값들의 개수입니다.\n",
    "\n",
    "        #argmax는 인풋으로 받은 행렬 중에서\n",
    "        #가장 값이 큰 인덱스를 반환합니다.\n",
    "        #즉, n이 m보다 크다면 n의 인덱스, 0을 반환합니다.\n",
    "        #이 인덱스는 결국 클래스를 나타내게 됩니다.\n",
    "        prediction[i][j] = np.argmax(np.bincount(neareast_class.reshape(k, )))\n",
    "print(\"prediction : \" +str(prediction.shape))\n",
    "print(\"successfully done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare prediction and real class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction result for each sample.\n",
      "k: 101\n",
      "sample: 1  accuracy: 78.10000000000001\n",
      "sample: 2  accuracy: 79.55\n",
      "sample: 3  accuracy: 77.60000000000001\n",
      "sample: 4  accuracy: 77.64999999999999\n",
      "sample: 5  accuracy: 77.2\n",
      "sample: 6  accuracy: 77.2\n",
      "sample: 7  accuracy: 77.10000000000001\n",
      "sample: 8  accuracy: 77.4\n",
      "sample: 9  accuracy: 77.4\n",
      "sample: 10  accuracy: 77.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 지정한 k 값들에 대해서 추정 값이 맞는지 확인합니다.\n",
    "\n",
    "print(\"prediction result for each sample.\")\n",
    "print(\"k: \" + str(101))\n",
    "isAnswer = np.empty((10, 2000))\n",
    "#isAnswer에는 정답 - 추정한 클래스 값이 들어가 있습니다. \n",
    "#즉, 요소가 0일 경우 해당 인덱스는 정답이고, \n",
    "#그 이외의 경우 오답입니다.\n",
    "isAnswer = sample_test_y - prediction.reshape(10, number_test, 1)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"sample: \" + str(i+1) +\"  accuracy: \"+str((np.count_nonzero(isAnswer[i] == 0)/number_test)*100))\n",
    "    \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting saving process..\n",
      "successfullt concatenated results...\n",
      "results saved to 20173709.csv\n",
      "successfully done.\n",
      "exit knn classifer 20173709\n"
     ]
    }
   ],
   "source": [
    "#저장된 결과를 csv파일로 저장합니다.\n",
    "#3차원으로 저장이 되어있기 때문에 2차원으로 변환해줍니다.\n",
    "#이때, 정답의 값과 추정값을 붙여서 출력합니다.\n",
    "\n",
    "print(\"starting saving process..\")\n",
    "result_class_prediction = np.empty((number_test, 0), int)\n",
    "for i in range(10):\n",
    "    concatenated = np.concatenate((sample_test_y[i], prediction[i].reshape(number_test, 1)), axis = 1)\n",
    "    result_class_prediction = np.concatenate((result_class_prediction, concatenated), axis = 1)\n",
    "print(\"successfully concatenated results...\")\n",
    "\n",
    "np.savetxt(\"20173709.csv\", result_class_prediction, fmt='%d', delimiter=',')\n",
    "print(\"results saved to 20173709.csv\")\n",
    "print(\"successfully done.\")\n",
    "print(\"exit knn classifer 20173709\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1aed0731b374a17b9f5237a21f75219259882e38811e96316e45347e29d5756"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
